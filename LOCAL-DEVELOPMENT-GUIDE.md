# n8n Local Development Guide

> Complete guide to developing and testing n8n workflows on your local PC
> Cost: $0 | Perfect for: 90%+ of workflow development
> Generated: 2025-11-24

## Table of Contents

- [Why Develop Locally?](#why-develop-locally)
- [Quick Start](#quick-start)
- [Setup Options](#setup-options)
- [Testing Strategies](#testing-strategies)
- [Mock Data Patterns](#mock-data-patterns)
- [Workflow Examples](#workflow-examples)
- [Webhook Testing](#webhook-testing)
- [Common Workflows by Type](#common-workflows-by-type)
- [Troubleshooting](#troubleshooting)
- [Deployment Path](#deployment-path)

---

## Why Develop Locally?

### âœ… Advantages

```
ğŸ’° COST: $0/month (vs $20-200/mo for n8n Cloud)
âš¡ SPEED: Instant iteration, no deploy delays
ğŸ”’ PRIVACY: Data never leaves your machine
ğŸ§ª TESTING: Unlimited executions, no quota
ğŸ“ LEARNING: Risk-free experimentation
ğŸ”§ DEBUGGING: Full access to logs and data
```

### ğŸ“Š What Works Locally

**90%+ of workflows can be fully developed and tested locally:**

| Feature | Works Locally | Notes |
|---------|--------------|-------|
| Manual triggers | âœ… Yes | Click and test instantly |
| Scheduled triggers | âœ… Yes | Test manually, validate logic |
| API calls (outbound) | âœ… Yes | Your PC calls external APIs |
| Database operations | âœ… Yes | Local or cloud databases |
| AI/LLM nodes | âœ… Yes | OpenAI, Anthropic, etc. |
| Data transformations | âœ… Yes | Code, Set, Switch nodes |
| Email sending | âœ… Yes | SMTP, Gmail, SendGrid |
| Notifications | âœ… Yes | Slack, Discord, etc. |
| File operations | âœ… Yes | Read, write, process files |
| HTTP Request | âœ… Yes | Call any API |
| **Inbound webhooks** | âš ï¸ Limited | Need ngrok or public URL |

**Only 10% needs production server**: Webhooks from external services (Stripe, GitHub, etc.)

---

## Quick Start

### Option 1: Docker (Recommended)

**Windows, Mac, Linux - All supported**

#### Install Docker

**Windows/Mac**:
- Download Docker Desktop: https://www.docker.com/products/docker-desktop

**Linux**:
```bash
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
```

#### Run n8n

**Simple Start (SQLite)**:
```bash
docker run -it --rm \
  --name n8n \
  -p 5678:5678 \
  -v ~/.n8n:/home/node/.n8n \
  n8nio/n8n
```

**Access**: http://localhost:5678

**Pros**:
- âœ… Clean, isolated environment
- âœ… Easy to restart
- âœ… Matches production setup
- âœ… No system pollution

**Cons**:
- âš ï¸ Requires Docker installed
- âš ï¸ 2-3GB disk space

### Option 2: npm (Direct Install)

**Requirements**: Node.js 18+ installed

```bash
# Install n8n globally
npm install n8n -g

# Run n8n
n8n start
```

**Access**: http://localhost:5678

**Pros**:
- âœ… Faster startup
- âœ… Direct access to files

**Cons**:
- âš ï¸ May conflict with other Node.js apps
- âš ï¸ Harder to clean up

---

## Setup Options

### Basic Setup (Development)

**Docker Compose** - Recommended for serious development

Create `docker-compose.yml`:

```yaml
version: '3.8'

services:
  n8n:
    image: n8nio/n8n
    restart: unless-stopped
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=false  # Disable for local dev
      - N8N_LOG_LEVEL=debug          # See all logs
      - GENERIC_TIMEZONE=America/New_York
      - N8N_EDITOR_BASE_URL=http://localhost:5678
    volumes:
      - n8n_data:/home/node/.n8n

volumes:
  n8n_data:
```

Run:
```bash
docker-compose up -d
```

Stop:
```bash
docker-compose down
```

View logs:
```bash
docker-compose logs -f n8n
```

### Advanced Setup (PostgreSQL)

**For testing production-like setup**

`docker-compose-advanced.yml`:

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15
    restart: unless-stopped
    environment:
      POSTGRES_USER: n8n
      POSTGRES_PASSWORD: n8n_password
      POSTGRES_DB: n8n
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"  # Expose for debugging

  n8n:
    image: n8nio/n8n
    restart: unless-stopped
    ports:
      - "5678:5678"
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=n8n
      - DB_POSTGRESDB_USER=n8n
      - DB_POSTGRESDB_PASSWORD=n8n_password
      - N8N_LOG_LEVEL=debug
      - GENERIC_TIMEZONE=America/New_York
    volumes:
      - n8n_data:/home/node/.n8n
    depends_on:
      - postgres

volumes:
  n8n_data:
  postgres_data:
```

Run:
```bash
docker-compose -f docker-compose-advanced.yml up -d
```

---

## Testing Strategies

### The Mock-First Approach

**Pattern**: Build entire workflow with mock data, then switch to real triggers.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DEVELOPMENT WORKFLOW                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 1: Build with Manual Trigger
    â†“
Manual Trigger
    â†“
Code Node (Generate mock data)
    â†“
[Your workflow logic]
    â†“
Test & iterate rapidly
    â†“
âœ… Perfect the logic

Phase 2: Switch to Real Trigger
    â†“
Replace Manual with Webhook/Schedule
    â†“
âœ… Deploy to production
```

### Example: API Integration Workflow

#### Step 1: Start with Manual Trigger

```javascript
// Workflow structure:
Manual Trigger
    â†“
HTTP Request (Fetch from API)
    â†“
Code (Transform)
    â†“
Google Sheets (Store)
    â†“
Slack (Notify)
```

**Test locally**:
1. Click "Test workflow"
2. See data flow through each node
3. Check transformations
4. Verify Sheets update
5. Confirm Slack notification

**All works locally!** âœ…

#### Step 2: Add Error Handling

```javascript
Manual Trigger
    â†“
HTTP Request (Fetch from API)
    â†“
IF (Check status code)
    â”œâ”€ Success â†’ Transform â†’ Store â†’ Notify
    â””â”€ Error â†’ Log Error â†’ Alert Team
```

**Test locally**:
1. Mock API failures
2. Verify error handling
3. Check error notifications

#### Step 3: Deploy

When perfect:
1. Save workflow
2. Export JSON
3. Import to production VPS
4. Change to Schedule trigger
5. Activate

---

## Mock Data Patterns

### Pattern 1: Mock External Webhooks

**Scenario**: Testing Stripe payment webhook

Instead of real Stripe webhook, use:

```javascript
// Node: Generate Mock Stripe Payment

const mockStripePayment = {
  id: "ch_test_12345",
  object: "charge",
  amount: 2999,
  currency: "usd",
  customer: "cus_test_12345",
  description: "Test Payment",
  metadata: {
    order_id: "order_123",
    customer_email: "test@example.com"
  },
  status: "succeeded",
  created: Math.floor(Date.now() / 1000)
};

return [{ json: mockStripePayment }];
```

**Full workflow**:

```
Manual Trigger
    â†“
Code (Generate mock Stripe data)
    â†“
[Process exactly as real webhook would]
    â†“
Code (Extract payment info)
    â†“
Email (Send receipt)
    â†“
Database (Update order)
```

**Benefits**:
- âœ… Test unlimited times
- âœ… Test edge cases (failed payments, refunds)
- âœ… No real charges
- âœ… No Stripe test mode needed

### Pattern 2: Mock API Responses

**Scenario**: Testing weather API integration

```javascript
// Node: Mock OpenWeather API Response

const mockWeatherData = {
  coord: { lon: -122.08, lat: 37.39 },
  weather: [
    {
      id: 800,
      main: "Clear",
      description: "clear sky",
      icon: "01d"
    }
  ],
  main: {
    temp: 282.55,
    feels_like: 281.86,
    temp_min: 280.37,
    temp_max: 284.26,
    pressure: 1023,
    humidity: 100
  },
  name: "Mountain View"
};

return [{ json: mockWeatherData }];
```

Use this instead of HTTP Request during development!

### Pattern 3: Mock Database Records

**Scenario**: Testing order processing workflow

```javascript
// Node: Mock Database Order

const mockOrders = [
  {
    order_id: "ORD-001",
    customer_name: "John Doe",
    email: "john@example.com",
    items: [
      { product: "Widget A", quantity: 2, price: 29.99 },
      { product: "Widget B", quantity: 1, price: 49.99 }
    ],
    total: 109.97,
    status: "pending",
    created_at: new Date().toISOString()
  },
  {
    order_id: "ORD-002",
    customer_name: "Jane Smith",
    email: "jane@example.com",
    items: [
      { product: "Gadget X", quantity: 1, price: 199.99 }
    ],
    total: 199.99,
    status: "pending",
    created_at: new Date().toISOString()
  }
];

return mockOrders.map(order => ({ json: order }));
```

### Pattern 4: Mock Time-Based Data

**Scenario**: Testing scheduled reports

```javascript
// Node: Generate Mock Time Series Data

const generateMockData = (days) => {
  const data = [];
  const now = new Date();

  for (let i = days - 1; i >= 0; i--) {
    const date = new Date(now);
    date.setDate(date.getDate() - i);

    data.push({
      date: date.toISOString().split('T')[0],
      revenue: Math.floor(Math.random() * 10000) + 5000,
      orders: Math.floor(Math.random() * 100) + 20,
      customers: Math.floor(Math.random() * 50) + 10
    });
  }

  return data;
};

const mockReportData = generateMockData(30);
return mockReportData.map(item => ({ json: item }));
```

---

## Workflow Examples

### Example 1: API Data Sync (100% Local Testable)

**Goal**: Fetch users from API, sync to Google Sheets

```
Manual Trigger
    â†“
HTTP Request
    URL: https://jsonplaceholder.typicode.com/users
    Method: GET
    â†“
Code (Transform data)
    // Extract only needed fields
    const users = $input.all();
    const formatted = users.map(user => ({
      json: {
        id: user.json.id,
        name: user.json.name,
        email: user.json.email,
        company: user.json.company.name
      }
    }));
    return formatted;
    â†“
Google Sheets
    Operation: Append
    Sheet: Users
    Range: A:D
    â†“
Slack
    Message: "âœ… Synced {{$json.length}} users to spreadsheet"
```

**Local Testing**:
1. Click "Test workflow"
2. See API call succeed
3. Verify data transformation
4. Check Google Sheets update
5. Confirm Slack notification

**All works on local PC!** No production server needed.

### Example 2: AI Content Generator (100% Local Testable)

**Goal**: Generate blog post ideas with OpenAI

```
Manual Trigger
    â†“
Edit Fields (Set)
    topic: "artificial intelligence"
    count: 5
    tone: "professional"
    â†“
OpenAI
    Operation: Chat
    Model: gpt-4o-mini
    Prompt: Generate {{$json.count}} blog post ideas about {{$json.topic}} in a {{$json.tone}} tone
    â†“
Code (Parse and structure)
    const response = $input.first().json.message.content;
    const ideas = response.split('\n').filter(line => line.trim());

    return ideas.map((idea, index) => ({
      json: {
        id: index + 1,
        idea: idea,
        topic: $('Edit Fields').item.json.topic,
        generated_at: new Date().toISOString()
      }
    }));
    â†“
Notion (or Google Sheets)
    Create page for each idea
```

**Local Testing**:
1. Set up OpenAI credentials (one-time)
2. Click "Test workflow"
3. See AI generate ideas
4. Verify parsing
5. Check Notion/Sheets update

**Works 100% locally with real OpenAI API!**

### Example 3: Data Processing Pipeline (100% Local Testable)

**Goal**: Process CSV file, clean data, generate report

```
Manual Trigger
    â†“
Read Binary File
    File Path: /home/node/.n8n/data/sales.csv
    â†“
Convert to JSON
    (Built-in CSV parser)
    â†“
Code (Clean and validate)
    const sales = $input.all();
    const cleaned = sales
      .filter(sale => sale.json.amount > 0)  // Remove invalid
      .map(sale => ({
        json: {
          date: sale.json.date,
          amount: parseFloat(sale.json.amount),
          product: sale.json.product.trim(),
          category: sale.json.category.toLowerCase()
        }
      }));
    return cleaned;
    â†“
Code (Calculate metrics)
    const items = $input.all();
    const total = items.reduce((sum, item) => sum + item.json.amount, 0);
    const count = items.length;
    const average = total / count;

    const byCategory = items.reduce((acc, item) => {
      const cat = item.json.category;
      acc[cat] = (acc[cat] || 0) + item.json.amount;
      return acc;
    }, {});

    return [{
      json: {
        total_sales: total,
        order_count: count,
        average_order: average,
        by_category: byCategory,
        generated_at: new Date().toISOString()
      }
    }];
    â†“
QuickChart (Generate chart)
    â†“
Email (Send report)
```

**Local Testing**:
1. Place CSV file in n8n directory
2. Click "Test workflow"
3. Verify data cleaning
4. Check calculations
5. See chart generation
6. Receive email with report

**Completely testable locally!**

### Example 4: Multi-API Integration (100% Local Testable)

**Goal**: Fetch GitHub issues, categorize with AI, create Notion tasks

```
Manual Trigger
    â†“
HTTP Request (GitHub API)
    URL: https://api.github.com/repos/owner/repo/issues
    Authentication: Bearer Token
    â†“
Code (Filter and prepare)
    const issues = $input.all();
    const openIssues = issues.filter(issue =>
      issue.json.state === 'open' && !issue.json.pull_request
    );
    return openIssues.map(issue => ({
      json: {
        title: issue.json.title,
        body: issue.json.body,
        url: issue.json.html_url,
        created: issue.json.created_at
      }
    }));
    â†“
OpenAI (Categorize)
    For each issue:
    Prompt: "Categorize this GitHub issue into one of: bug, feature, documentation, question. Issue: {{$json.title}} - {{$json.body}}"
    â†“
Code (Structure for Notion)
    const items = $input.all();
    return items.map(item => ({
      json: {
        title: item.json.title,
        category: item.json.message.content.trim().toLowerCase(),
        url: item.json.url,
        status: "To Do"
      }
    }));
    â†“
Notion (Create database items)
    Database: GitHub Issues
    Properties:
      - Title: {{$json.title}}
      - Category: {{$json.category}}
      - URL: {{$json.url}}
      - Status: {{$json.status}}
```

**Local Testing**:
1. Set up GitHub + OpenAI + Notion credentials
2. Click "Test workflow"
3. See GitHub API fetch
4. Watch AI categorization
5. Verify Notion creation

**All APIs work from local PC!**

---

## Webhook Testing

### When You Need It

Only when testing **inbound webhooks** from external services:
- Payment notifications (Stripe, PayPal)
- Repository events (GitHub, GitLab)
- Form submissions
- Chat messages (Slack bot events)

### Option 1: ngrok (Free, Easy)

**Install ngrok**:
```bash
# Download from: https://ngrok.com/download
# Or use package managers:

# Mac
brew install ngrok

# Windows (Chocolatey)
choco install ngrok

# Linux
curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | \
  sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null && \
  echo "deb https://ngrok-agent.s3.amazonaws.com buster main" | \
  sudo tee /etc/apt/sources.list.d/ngrok.list && \
  sudo apt update && sudo apt install ngrok
```

**Use ngrok**:

```bash
# Terminal 1: Run n8n
docker run -p 5678:5678 n8nio/n8n

# Terminal 2: Expose to internet
ngrok http 5678
```

**Output**:
```
ngrok

Session Status                online
Account                       user@example.com (Plan: Free)
Version                       3.0.0
Region                        United States (us)
Latency                       -
Web Interface                 http://127.0.0.1:4040
Forwarding                    https://abc123.ngrok.io -> http://localhost:5678

Connections                   ttl     opn     rt1     rt5     p50     p90
                              0       0       0.00    0.00    0.00    0.00
```

**Use URL**: `https://abc123.ngrok.io`

**In n8n webhook node**:
```
Webhook URL: https://abc123.ngrok.io/webhook/your-path
```

**Configure in external service**:
```
Stripe webhook: https://abc123.ngrok.io/webhook/stripe-payment
GitHub webhook: https://abc123.ngrok.io/webhook/github-push
```

**Pros**:
- âœ… Free tier available
- âœ… Instant public URL
- âœ… HTTPS included
- âœ… Request inspector (http://127.0.0.1:4040)

**Cons**:
- âš ï¸ URL changes on restart (free tier)
- âš ï¸ 60-minute timeout (free tier)
- âš ï¸ Limited bandwidth

### Option 2: LocalTunnel (Free, No Signup)

**Install**:
```bash
npm install -g localtunnel
```

**Use**:
```bash
# Run n8n
docker run -p 5678:5678 n8nio/n8n

# Expose
lt --port 5678
```

**Output**:
```
your url is: https://smart-moose-12.loca.lt
```

**Pros**:
- âœ… Completely free
- âœ… No signup required
- âœ… Simple

**Cons**:
- âš ï¸ Less reliable
- âš ï¸ Slower
- âš ï¸ URL changes

### Option 3: Cloudflare Tunnel (Free, Best for Long-term)

**Install**:
```bash
# Download from: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/install-and-setup/installation/
```

**Setup**:
```bash
cloudflared tunnel --url http://localhost:5678
```

**Pros**:
- âœ… Free
- âœ… Fast (Cloudflare CDN)
- âœ… Reliable
- âœ… Custom domains possible

**Cons**:
- âš ï¸ More setup required
- âš ï¸ Need Cloudflare account

### Webhook Testing Workflow

```
1. Build workflow with Manual Trigger + Mock Data
    â†“
2. Perfect all logic locally
    â†“
3. When ready, switch to Webhook Trigger
    â†“
4. Start ngrok
    â†“
5. Configure webhook in external service
    â†“
6. Test 1-2 real webhooks
    â†“
7. Verify payload matches mock
    â†“
8. Deploy to production VPS
```

---

## Common Workflows by Type

### API Integration Workflows (100% Local)

**Pattern**:
```
Trigger (Manual/Schedule)
    â†“
HTTP Request (Call external API)
    â†“
Process data
    â†“
Store/Notify
```

**Examples that work locally**:
- âœ… Weather data fetching
- âœ… Stock price tracking
- âœ… Social media posting
- âœ… CRM data sync
- âœ… Analytics retrieval

### AI/LLM Workflows (100% Local)

**Pattern**:
```
Trigger
    â†“
Prepare prompt
    â†“
AI Node (OpenAI/Claude/etc.)
    â†“
Process response
    â†“
Store/Send
```

**Examples**:
- âœ… Content generation
- âœ… Text summarization
- âœ… Sentiment analysis
- âœ… Translation
- âœ… Classification

### Data Processing Workflows (100% Local)

**Pattern**:
```
Trigger
    â†“
Read data source
    â†“
Transform/Clean
    â†“
Calculate/Aggregate
    â†“
Output
```

**Examples**:
- âœ… CSV processing
- âœ… Report generation
- âœ… Data validation
- âœ… File conversions
- âœ… Batch operations

### Notification Workflows (100% Local)

**Pattern**:
```
Trigger
    â†“
Check conditions
    â†“
Format message
    â†“
Send notification
```

**Examples**:
- âœ… Slack alerts
- âœ… Email notifications
- âœ… Discord messages
- âœ… SMS via Twilio
- âœ… Push notifications

### Webhook Workflows (Need ngrok/VPS)

**Pattern**:
```
Webhook Trigger (from external service)
    â†“
Process payload
    â†“
Take action
```

**Examples**:
- âš ï¸ Stripe payments
- âš ï¸ GitHub events
- âš ï¸ Form submissions
- âš ï¸ Chat bot messages

**Testing**: Use mock data locally, then ngrok for final test

---

## Troubleshooting

### Docker Issues

**Problem**: "Cannot connect to Docker daemon"

**Solution**:
```bash
# Windows/Mac: Start Docker Desktop
# Linux: Start Docker service
sudo systemctl start docker
```

**Problem**: Port 5678 already in use

**Solution**:
```bash
# Use different port
docker run -p 5679:5678 n8nio/n8n

# Or kill process using 5678
# Windows
netstat -ano | findstr :5678
taskkill /PID <PID> /F

# Mac/Linux
lsof -ti:5678 | xargs kill -9
```

### Access Issues

**Problem**: Can't access http://localhost:5678

**Solution**:
```bash
# Check if container is running
docker ps

# Check logs
docker logs n8n

# Try 127.0.0.1 instead
http://127.0.0.1:5678
```

### Workflow Execution Issues

**Problem**: "Can't get data for expression"

**Solution**:
- Execute workflow up to that node first
- Check node connections
- Verify previous node executed successfully

**Problem**: API credentials not working

**Solution**:
```bash
# Check credential setup
# Test with curl first:
curl -H "Authorization: Bearer YOUR_TOKEN" https://api.example.com/test

# Verify in n8n:
# Settings â†’ Credentials â†’ Test connection
```

### Performance Issues

**Problem**: Slow execution

**Solution**:
```bash
# Allocate more memory to Docker
# Docker Desktop â†’ Settings â†’ Resources â†’ Memory: 4GB+

# Or use docker-compose with resource limits:
services:
  n8n:
    deploy:
      resources:
        limits:
          memory: 2G
```

---

## Deployment Path

### From Local to Production

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 1: Local Development                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Environment: Your PC (Docker)                       â”‚
â”‚ Duration: 1-4 weeks                                 â”‚
â”‚ Cost: $0                                            â”‚
â”‚                                                     â”‚
â”‚ Activities:                                         â”‚
â”‚ âœ… Learn n8n interface                              â”‚
â”‚ âœ… Build workflows                                  â”‚
â”‚ âœ… Test with mock data                              â”‚
â”‚ âœ… Connect to APIs                                  â”‚
â”‚ âœ… Set up integrations                              â”‚
â”‚ âœ… Debug and iterate                                â”‚
â”‚ âœ… Perfect all logic                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 2: Webhook Testing (Optional)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Environment: Local + ngrok                          â”‚
â”‚ Duration: 1-3 days                                  â”‚
â”‚ Cost: $0                                            â”‚
â”‚                                                     â”‚
â”‚ Activities:                                         â”‚
â”‚ âœ… Start ngrok                                      â”‚
â”‚ âœ… Configure webhooks in external services          â”‚
â”‚ âœ… Test real webhook payloads                       â”‚
â”‚ âœ… Verify integration                               â”‚
â”‚ âœ… Document payload structure                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 3: Production Deployment                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Environment: Hostinger VPS                          â”‚
â”‚ Duration: Forever (24/7)                            â”‚
â”‚ Cost: $10-15/mo                                     â”‚
â”‚                                                     â”‚
â”‚ Setup:                                              â”‚
â”‚ 1. Order Hostinger VPS                              â”‚
â”‚ 2. Install Docker + Docker Compose                  â”‚
â”‚ 3. Set up PostgreSQL database                       â”‚
â”‚ 4. Configure domain and SSL                         â”‚
â”‚ 5. Deploy n8n stack                                 â”‚
â”‚                                                     â”‚
â”‚ Migration:                                          â”‚
â”‚ 1. Export workflows from local                      â”‚
â”‚ 2. Import to production                             â”‚
â”‚ 3. Update credentials                               â”‚
â”‚ 4. Activate workflows                               â”‚
â”‚ 5. Monitor executions                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Export/Import Process

**Export from local**:
```
n8n UI â†’ Workflows â†’ Select All â†’ Download
    â†“
Saves workflows-export.json
```

**Import to production**:
```
Production n8n â†’ Workflows â†’ Import from file
    â†“
Upload workflows-export.json
    â†“
Update any environment-specific settings
    â†“
Activate workflows
```

### Pre-Deployment Checklist

```
Local Development Complete:
â–¡ All workflows tested
â–¡ All integrations working
â–¡ Credentials documented
â–¡ Error handling verified
â–¡ Mock data matches real data structure

Ready for Production:
â–¡ VPS provisioned
â–¡ Domain configured
â–¡ SSL certificate obtained
â–¡ PostgreSQL database set up
â–¡ Backup strategy defined
â–¡ Monitoring plan ready

Post-Deployment:
â–¡ Workflows imported
â–¡ Credentials configured
â–¡ Test executions run
â–¡ Webhooks configured
â–¡ Monitoring active
â–¡ Team notified
```

---

## Best Practices

### 1. Use Version Control for Workflows

```bash
# Export regularly
mkdir -p ~/n8n-workflows
cd ~/n8n-workflows
git init

# Export from n8n and save
# Commit changes
git add .
git commit -m "Update: Add customer notification workflow"
git push
```

### 2. Document Your Workflows

Add notes to workflow descriptions:
```
Workflow Name: Daily Sales Report
Description:
- Fetches sales data from PostgreSQL
- Calculates daily metrics
- Generates chart with QuickChart
- Emails report to team@example.com
- Runs: Daily at 9:00 AM EST
- Dependencies: PostgreSQL, SendGrid, QuickChart
```

### 3. Use Environment-Specific Variables

Create workflow variables:
```javascript
// Code node: Set environment
const ENV = 'local'; // Change to 'production' when deployed

const config = {
  local: {
    apiUrl: 'http://localhost:3000/api',
    webhookUrl: 'https://abc123.ngrok.io'
  },
  production: {
    apiUrl: 'https://api.example.com',
    webhookUrl: 'https://n8n.example.com'
  }
};

return [{ json: config[ENV] }];
```

### 4. Test Edge Cases

Mock different scenarios:
```javascript
// Test successful case
// Test with missing data
// Test with invalid data
// Test with empty response
// Test with API errors
// Test with timeout

const scenarios = [
  { type: 'success', data: {...} },
  { type: 'missing_field', data: {...} },
  { type: 'invalid_format', data: {...} },
  { type: 'empty', data: [] },
  { type: 'error', status: 500 }
];

// Test each scenario
```

### 5. Keep Workflows Modular

Break complex workflows into smaller, reusable pieces:
```
Main Workflow
    â†“
Execute Workflow: Data Fetcher
Execute Workflow: Data Processor
Execute Workflow: Notifier
```

---

## Summary

### Local Development Advantages

| Aspect | Local | Production |
|--------|-------|------------|
| **Cost** | $0 | $10-200/mo |
| **Setup Time** | 5 minutes | 1-2 hours |
| **Iteration Speed** | Instant | Deploy delay |
| **Learning Curve** | Risk-free | Higher stakes |
| **Debugging** | Full access | Limited |
| **Data Privacy** | Complete | Depends |

### What You Can Do Locally

âœ… **90%+ of workflow development**:
- API integrations
- Data transformations
- AI/LLM processing
- Database operations
- Email/notifications
- Scheduled tasks (test manually)
- File operations
- Most integrations

âŒ **Only 10% needs production**:
- Inbound webhooks from external services

### Quick Reference

**Start n8n**:
```bash
docker run -p 5678:5678 n8nio/n8n
```

**Access**: http://localhost:5678

**Test webhooks**:
```bash
ngrok http 5678
```

**Deploy when ready**:
1. Export workflows
2. Set up production VPS
3. Import workflows
4. Activate

---

**Next Steps**:
1. Start Docker
2. Run n8n locally
3. Import hello-world.json from `workflows/` folder
4. Start building!

**Resources**:
- `workflows/` - Example workflows
- `brain/brain-unified.md` - Complete n8n knowledge
- `WORKFLOW-ANALYSIS.md` - Field analysis

**Cost to start**: $0
**Time to start**: 5 minutes
**Workflows you can build locally**: 90%+

ğŸš€ **Start developing locally today!**
